# -*- coding: utf-8 -*-
"""21100187-21100124-MLProject

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i0uN7k_i1-c_DcGRQ6mRIxbgSP_yS7M4
"""

# FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)

# HomeTeam = ghar Team 
# AwayTeam = Away Team

# (HTHG = Half Time Home Team Goals + HTAG = Half Time Away Team Goals)

# -- OR -- 

# HTR = Half Time Result (H=Home Win, D=Draw, A=Away Win)



# FTHG = Full Time Home Team Goals X
# FTAG = Full Time Away Team Goals X

# Match Statistics (where available)
# Attendance = Crowd Attendance
# Referee = Match Referee
# HS = Home Team Shots
# AS = Away Team Shots
# HST = Home Team Shots on Target
# AST = Away Team Shots on Target
# HHW = Home Team Hit Woodwork
# AHW = Away Team Hit Woodwork
# HC = Home Team Corners
# AC = Away Team Corners
# HF = Home Team Fouls Committed
# AF = Away Team Fouls Committed
# HO = Home Team Offsides
# AO = Away Team Offsides


# HY = Home Team Yellow Cards
# AY = Away Team Yellow Cards
# HR = Home Team Red Cards
# AR = Away Team Red Cards

# -- OR --

# HBP = Home Team Bookings Points (10 = yellow, 25 = red)
# ABP = Away Team Bookings Points (10 = yellow, 25 = red)

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import os
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import GaussianNB

data_path = '/content/drive/MyDrive/ML_EPL/'
files = os.listdir(data_path)

begun = 0
for fille in files:
  if fille.split('.')[-1] == 'csv':
    if begun == 0: 
      dataset00 = pd.read_csv(data_path + fille)  
      begun = 1
    else:
      dataset00 = dataset00.append(pd.read_csv(data_path + fille),ignore_index=True)

print(len(dataset00))
dataset00.shape

dataset00 = dataset00.iloc[:,:23]
dataset00.dropna(axis=0,inplace=True)
dataset00

team_list = np.array(dataset00['HomeTeam'].append(dataset00['AwayTeam'], ignore_index=True).drop_duplicates(inplace=False))         
referee_list = np.array(dataset00['Referee'].drop_duplicates(inplace=False))                                                        
result_list = np.array(['H','D','A'])                                                                                                       

for i in range(len(dataset00)):                                                                                                             
  dataset00['HomeTeam'].iloc[i] = np.where(team_list == dataset00['HomeTeam'].iloc[i])[0][0]                                              
  dataset00['AwayTeam'].iloc[i] = np.where(team_list == dataset00['AwayTeam'].iloc[i])[0][0]

  dataset00['Referee'].iloc[i] = np.where(referee_list == dataset00['Referee'].iloc[i])[0][0]                                                                   
  dataset00['FTR'].iloc[i] = np.where(result_list == dataset00['FTR'].iloc[i])[0][0]                                                                
  dataset00['HTR'].iloc[i] = np.where(result_list == dataset00['HTR'].iloc[i])[0][0]                                                                        

dataset00.drop(labels=['Div','Date',"FTHG","FTAG","Referee"],axis=1,inplace=True)                                                                                     

dataset00.head()

tbn = ['HTHG','HTAG','HS','AS','HST','AST','HC','AC','HF','AF','HY','AY','HR','AR']


for t in tbn: #Std normal
  dataset00[t] = (dataset00[t] - dataset00[t].mean()) / dataset00[t].std()

# for t in tbn: #0-1 normal
#   dataset00[t] = (dataset00[t] - dataset00[t].min()) / ((dataset00[t] - dataset00[t].min()).max())

dataset00.head(5)

plt.figure(figsize=(25, 25))
heatmap = sns.heatmap(dataset00.corr('pearson'), vmin=-1, vmax=1, annot=True)

tt_split = 0.9

y_train = dataset00[:int(tt_split * np.shape(dataset00)[0])]['FTR']
y_test  = dataset00[int(tt_split * np.shape(dataset00)[0]):]['FTR']

x_train = dataset00[:int(tt_split * np.shape(dataset00)[0])].drop(labels=['FTR'], axis=1)
x_test  = dataset00[int(tt_split * np.shape(dataset00)[0]):].drop(labels=['FTR'], axis=1)

val_split = 0.8

y_val  = y_train[int(val_split * np.shape(dataset00)[0]):].reset_index().drop(labels=['index'],axis=1)
y_train = y_train[:int(val_split * np.shape(dataset00)[0])]

x_val  = x_train[int(val_split * np.shape(dataset00)[0]):].reset_index().drop(labels=['index'],axis=1)
x_train = x_train[:int(val_split * np.shape(dataset00)[0])]

np.shape(x_train), np.shape(y_train), np.shape(x_val), np.shape(y_val)

x_train.head(2)

def evaluate_nayyer(x,y,model):

  points = np.shape(x)[0]
  points_accounted = points
  features = np.shape(x)[1]

  correct_predictions = 0

  for s in range(points):  
    try:
      y_pred = model.predict(np.array(x)[s].astype(np.float).reshape(1,features))[0]
      y_label = np.array(y)[s].astype(np.float)

      if y_pred == y_label:
        correct_predictions += 1


    except:
      points_accounted -= 1

  acc = correct_predictions / points

  return acc, points_accounted/points

clf = GaussianNB()
clf.fit(np.array(x_train).astype(np.float), np.array(y_train).astype(np.float))

evaluate_nayyer(x_val, y_val, clf)

evaluate_nayyer(x_test, y_test, clf)

from sklearn.neighbors import KNeighborsClassifier

neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(np.array(x_train).astype(np.float), np.array(y_train).astype(np.float))

evaluate_nayyer(x_val, y_val, neigh)

evaluate_nayyer(x_test, y_test, neigh)

from sklearn.linear_model import LogisticRegression

logi = LogisticRegression(random_state=0,max_iter=1000)
logi.fit(np.array(x_train).astype(np.float), np.array(y_train).astype(np.float))

evaluate_nayyer(x_val,y_val,logi)

evaluate_nayyer(x_test,y_test,logi)